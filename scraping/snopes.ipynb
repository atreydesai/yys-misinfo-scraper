{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following fact-check URLs on page 1:\n",
      "https://www.snopes.com/fact-check/trump-musk-nyc-protest/\n",
      "https://www.snopes.com/fact-check/video-bugs-pringles-chip/\n",
      "https://www.snopes.com/fact-check/dog-train-tracks-tiktok-video/\n",
      "https://www.snopes.com/fact-check/video-crowd-celebrating-trump-mugshot/\n",
      "https://www.snopes.com/fact-check/voter-fraud-in-2016-primary/\n",
      "https://www.snopes.com/fact-check/europa-io-jupiter-video/\n",
      "https://www.snopes.com/fact-check/1908-olympics-video/\n",
      "https://www.snopes.com/fact-check/us-cargo-ship-houthi-missile/\n",
      "https://www.snopes.com/fact-check/trump-project-2025-roberts/\n",
      "https://www.snopes.com/fact-check/polo-blow/\n",
      "https://www.snopes.com/fact-check/video-zelenskyy-dancing-high-heels/\n",
      "https://www.snopes.com/fact-check/elephant-seal-chilean-town/\n",
      "https://www.snopes.com/fact-check/video-snowy-owl-carrying-chicks/\n",
      "https://www.snopes.com/fact-check/officer-nakia-jones-fired-after-viral-police-brutality-video/\n",
      "Found the following fact-check URLs on page 2:\n",
      "https://www.snopes.com/fact-check/trump-retweet-cowboys/\n",
      "https://www.snopes.com/fact-check/video-of-a-globular-bolt-real/\n",
      "https://www.snopes.com/fact-check/escape-from-buckingham-palace/\n",
      "https://www.snopes.com/fact-check/giant-moon-blocking-sun-arctic/\n",
      "https://www.snopes.com/fact-check/ants-termites-standoff/\n",
      "https://www.snopes.com/fact-check/baby-giraffe-video/\n",
      "https://www.snopes.com/fact-check/trump-peacefully-and-patriotically/\n",
      "https://www.snopes.com/fact-check/bear-vs-bike/\n",
      "https://www.snopes.com/fact-check/fake-video-sea-white-octopus/\n",
      "https://www.snopes.com/fact-check/video-newt-rapidly-changing-color/\n",
      "https://www.snopes.com/fact-check/microscope-video-bugs-oreo-cookie/\n",
      "https://www.snopes.com/fact-check/robots-dancing-shanghai-disneyland/\n",
      "https://www.snopes.com/fact-check/baby-peacock-video/\n",
      "https://www.snopes.com/fact-check/c-span-video-joe-biden-ukraine/\n",
      "https://www.snopes.com/fact-check/russian-nukes-near-finland/\n",
      "Found the following fact-check URLs on page 3:\n",
      "https://www.snopes.com/fact-check/is-this-ghost-of-kyiv-video-real/\n",
      "https://www.snopes.com/fact-check/north-korea-internet-video/\n",
      "https://www.snopes.com/fact-check/obama-admits-kenya-birth/\n",
      "https://www.snopes.com/fact-check/dolphin-bubbles-rings-video/\n",
      "https://www.snopes.com/fact-check/video-headlines-immigrants-eating-cats/\n",
      "https://www.snopes.com/fact-check/violent-aftermath-of-coronavirus/\n",
      "https://www.snopes.com/fact-check/if-youre-a-fetus-and-you-know-it/\n",
      "https://www.snopes.com/fact-check/hurricane-idalia-clearwater-beach-florida/\n",
      "https://www.snopes.com/fact-check/boston-dynamics-robot-fighting-video/\n",
      "https://www.snopes.com/fact-check/athletes-fainting-covid-19-vaccine/\n",
      "https://www.snopes.com/fact-check/ribbon-worm-video/\n",
      "https://www.snopes.com/fact-check/baby-recognizes-mothers-heart/\n",
      "Found the following fact-check URLs on page 4:\n",
      "https://www.snopes.com/fact-check/large-leatherback-turtle-video/\n",
      "https://www.snopes.com/fact-check/mike-tyson-time-traveler/\n",
      "https://www.snopes.com/fact-check/dolphin-rescues-dog-video/\n",
      "https://www.snopes.com/fact-check/lion-revenge-trophy-hunter-video/\n",
      "https://www.snopes.com/fact-check/finland-moving-tanks-border/\n",
      "https://www.snopes.com/fact-check/kim-putin-toast/\n",
      "https://www.snopes.com/fact-check/rocket-moon/\n",
      "https://www.snopes.com/fact-check/unidentified-drone-new-jersey-video-icemanfox1/\n",
      "https://www.snopes.com/fact-check/hot-dog-under-microscope/\n",
      "https://www.snopes.com/fact-check/video-tiger-chasing-motorcycle/\n",
      "https://www.snopes.com/fact-check/crisis-actors-propaganda-ukraine/\n",
      "https://www.snopes.com/fact-check/plane-loses-wing/\n",
      "https://www.snopes.com/fact-check/ye-t-shirt-jewish-celebrities/\n",
      "Found the following fact-check URLs on page 5:\n",
      "https://www.snopes.com/fact-check/robot-doing-military-drills/\n",
      "https://www.snopes.com/fact-check/putin-deepfake-russian-surrender/\n",
      "https://www.snopes.com/fact-check/moonrise-byron-bay-video/\n",
      "https://www.snopes.com/fact-check/marines-jetpacks-video/\n",
      "https://www.snopes.com/fact-check/sunak-candles-video/\n",
      "https://www.snopes.com/fact-check/live-action-spirited-away-series/\n",
      "https://www.snopes.com/fact-check/biden-white-americans-video/\n",
      "https://www.snopes.com/fact-check/trump-waving-at-no-one/\n",
      "https://www.snopes.com/fact-check/pp-baby-parts-sale/\n",
      "https://www.snopes.com/fact-check/high-diving-giraffe-video/\n",
      "https://www.snopes.com/fact-check/starbucks-cup-size-scam/\n",
      "https://www.snopes.com/fact-check/eagle-carrying-a-shark-video/\n",
      "https://www.snopes.com/fact-check/tom-brady-video-catch-machine/\n",
      "https://www.snopes.com/fact-check/sucker-punch/\n",
      "Found the following fact-check URLs on page 6:\n",
      "https://www.snopes.com/fact-check/baby-olympics-video/\n",
      "https://www.snopes.com/fact-check/microscope-bugs-instant-ramen-video/\n",
      "https://www.snopes.com/fact-check/zombie-chicken-video/\n",
      "https://www.snopes.com/fact-check/clip-artless/\n",
      "https://www.snopes.com/fact-check/viral-molten-copper-big-mac/\n",
      "https://www.snopes.com/fact-check/gabby-petito-video-sandy-hook/\n",
      "https://www.snopes.com/fact-check/ice-helix-polar-vortex-video/\n",
      "https://www.snopes.com/fact-check/kyle-rittenhouse-punch-woman-video/\n",
      "https://www.snopes.com/fact-check/hurricane-dorian-near-florida/\n",
      "https://www.snopes.com/fact-check/scarlett-johansson-woman-disappears/\n",
      "https://www.snopes.com/fact-check/video-indonesia-cloud/\n",
      "https://www.snopes.com/fact-check/cnn-israel-exploding-goats-hezbollah/\n",
      "https://www.snopes.com/fact-check/trump-northam-abortion-execute/\n",
      "Found the following fact-check URLs on page 7:\n",
      "https://www.snopes.com/fact-check/footage-inside-plane-crashed-nepal/\n",
      "https://www.snopes.com/fact-check/video-volcano-iceland/\n",
      "https://www.snopes.com/fact-check/amazing-catch-ball-girl/\n",
      "https://www.snopes.com/fact-check/double-trouble/\n",
      "https://www.snopes.com/fact-check/video-bye-bye/\n",
      "https://www.snopes.com/fact-check/baby-dunking-video/\n",
      "https://www.snopes.com/fact-check/abc-video-syrian-war-footage/\n",
      "https://www.snopes.com/fact-check/false-footaging/\n",
      "https://www.snopes.com/fact-check/asteroid-moon-collision/\n",
      "https://www.snopes.com/fact-check/churchill-waterslide-video/\n",
      "https://www.snopes.com/fact-check/puppy-butterfly-video-real/\n",
      "https://www.snopes.com/fact-check/avoiding-future-plague-psa/\n",
      "https://www.snopes.com/fact-check/real-video-arrow-always-points-right/\n",
      "An error occurred: Message: \n",
      "Stacktrace:\n",
      "#0 0x55afe175dbea <unknown>\n",
      "#1 0x55afe11fb7d0 <unknown>\n",
      "#2 0x55afe124ccc0 <unknown>\n",
      "#3 0x55afe124ce41 <unknown>\n",
      "#4 0x55afe129b984 <unknown>\n",
      "#5 0x55afe1272abd <unknown>\n",
      "#6 0x55afe1298d0c <unknown>\n",
      "#7 0x55afe1272863 <unknown>\n",
      "#8 0x55afe123eac8 <unknown>\n",
      "#9 0x55afe123fc31 <unknown>\n",
      "#10 0x55afe172718b <unknown>\n",
      "#11 0x55afe172b112 <unknown>\n",
      "#12 0x55afe171404c <unknown>\n",
      "#13 0x55afe172bd04 <unknown>\n",
      "#14 0x55afe16f84bf <unknown>\n",
      "#15 0x55afe174c528 <unknown>\n",
      "#16 0x55afe174c6f9 <unknown>\n",
      "#17 0x55afe175ca66 <unknown>\n",
      "#18 0x7f77780311ca start_thread\n",
      "\n",
      "No fact-check URLs found on page 8.\n",
      "An error occurred: Message: \n",
      "Stacktrace:\n",
      "#0 0x55a68e437bea <unknown>\n",
      "#1 0x55a68ded57d0 <unknown>\n",
      "#2 0x55a68df26cc0 <unknown>\n",
      "#3 0x55a68df26e41 <unknown>\n",
      "#4 0x55a68df75984 <unknown>\n",
      "#5 0x55a68df4cabd <unknown>\n",
      "#6 0x55a68df72d0c <unknown>\n",
      "#7 0x55a68df4c863 <unknown>\n",
      "#8 0x55a68df18ac8 <unknown>\n",
      "#9 0x55a68df19c31 <unknown>\n",
      "#10 0x55a68e40118b <unknown>\n",
      "#11 0x55a68e405112 <unknown>\n",
      "#12 0x55a68e3ee04c <unknown>\n",
      "#13 0x55a68e405d04 <unknown>\n",
      "#14 0x55a68e3d24bf <unknown>\n",
      "#15 0x55a68e426528 <unknown>\n",
      "#16 0x55a68e4266f9 <unknown>\n",
      "#17 0x55a68e436a66 <unknown>\n",
      "#18 0x7f6a7e7911ca start_thread\n",
      "\n",
      "No fact-check URLs found on page 9.\n",
      "\n",
      "All collected URLs:\n",
      "['https://www.snopes.com/fact-check/trump-musk-nyc-protest/', 'https://www.snopes.com/fact-check/video-bugs-pringles-chip/', 'https://www.snopes.com/fact-check/dog-train-tracks-tiktok-video/', 'https://www.snopes.com/fact-check/video-crowd-celebrating-trump-mugshot/', 'https://www.snopes.com/fact-check/voter-fraud-in-2016-primary/', 'https://www.snopes.com/fact-check/europa-io-jupiter-video/', 'https://www.snopes.com/fact-check/1908-olympics-video/', 'https://www.snopes.com/fact-check/us-cargo-ship-houthi-missile/', 'https://www.snopes.com/fact-check/trump-project-2025-roberts/', 'https://www.snopes.com/fact-check/polo-blow/', 'https://www.snopes.com/fact-check/video-zelenskyy-dancing-high-heels/', 'https://www.snopes.com/fact-check/elephant-seal-chilean-town/', 'https://www.snopes.com/fact-check/video-snowy-owl-carrying-chicks/', 'https://www.snopes.com/fact-check/officer-nakia-jones-fired-after-viral-police-brutality-video/', 'https://www.snopes.com/fact-check/trump-retweet-cowboys/', 'https://www.snopes.com/fact-check/video-of-a-globular-bolt-real/', 'https://www.snopes.com/fact-check/escape-from-buckingham-palace/', 'https://www.snopes.com/fact-check/giant-moon-blocking-sun-arctic/', 'https://www.snopes.com/fact-check/ants-termites-standoff/', 'https://www.snopes.com/fact-check/baby-giraffe-video/', 'https://www.snopes.com/fact-check/trump-peacefully-and-patriotically/', 'https://www.snopes.com/fact-check/bear-vs-bike/', 'https://www.snopes.com/fact-check/fake-video-sea-white-octopus/', 'https://www.snopes.com/fact-check/video-newt-rapidly-changing-color/', 'https://www.snopes.com/fact-check/microscope-video-bugs-oreo-cookie/', 'https://www.snopes.com/fact-check/robots-dancing-shanghai-disneyland/', 'https://www.snopes.com/fact-check/baby-peacock-video/', 'https://www.snopes.com/fact-check/c-span-video-joe-biden-ukraine/', 'https://www.snopes.com/fact-check/russian-nukes-near-finland/', 'https://www.snopes.com/fact-check/is-this-ghost-of-kyiv-video-real/', 'https://www.snopes.com/fact-check/north-korea-internet-video/', 'https://www.snopes.com/fact-check/obama-admits-kenya-birth/', 'https://www.snopes.com/fact-check/dolphin-bubbles-rings-video/', 'https://www.snopes.com/fact-check/video-headlines-immigrants-eating-cats/', 'https://www.snopes.com/fact-check/violent-aftermath-of-coronavirus/', 'https://www.snopes.com/fact-check/if-youre-a-fetus-and-you-know-it/', 'https://www.snopes.com/fact-check/hurricane-idalia-clearwater-beach-florida/', 'https://www.snopes.com/fact-check/boston-dynamics-robot-fighting-video/', 'https://www.snopes.com/fact-check/athletes-fainting-covid-19-vaccine/', 'https://www.snopes.com/fact-check/ribbon-worm-video/', 'https://www.snopes.com/fact-check/baby-recognizes-mothers-heart/', 'https://www.snopes.com/fact-check/large-leatherback-turtle-video/', 'https://www.snopes.com/fact-check/mike-tyson-time-traveler/', 'https://www.snopes.com/fact-check/dolphin-rescues-dog-video/', 'https://www.snopes.com/fact-check/lion-revenge-trophy-hunter-video/', 'https://www.snopes.com/fact-check/finland-moving-tanks-border/', 'https://www.snopes.com/fact-check/kim-putin-toast/', 'https://www.snopes.com/fact-check/rocket-moon/', 'https://www.snopes.com/fact-check/unidentified-drone-new-jersey-video-icemanfox1/', 'https://www.snopes.com/fact-check/hot-dog-under-microscope/', 'https://www.snopes.com/fact-check/video-tiger-chasing-motorcycle/', 'https://www.snopes.com/fact-check/crisis-actors-propaganda-ukraine/', 'https://www.snopes.com/fact-check/plane-loses-wing/', 'https://www.snopes.com/fact-check/ye-t-shirt-jewish-celebrities/', 'https://www.snopes.com/fact-check/robot-doing-military-drills/', 'https://www.snopes.com/fact-check/putin-deepfake-russian-surrender/', 'https://www.snopes.com/fact-check/moonrise-byron-bay-video/', 'https://www.snopes.com/fact-check/marines-jetpacks-video/', 'https://www.snopes.com/fact-check/sunak-candles-video/', 'https://www.snopes.com/fact-check/live-action-spirited-away-series/', 'https://www.snopes.com/fact-check/biden-white-americans-video/', 'https://www.snopes.com/fact-check/trump-waving-at-no-one/', 'https://www.snopes.com/fact-check/pp-baby-parts-sale/', 'https://www.snopes.com/fact-check/high-diving-giraffe-video/', 'https://www.snopes.com/fact-check/starbucks-cup-size-scam/', 'https://www.snopes.com/fact-check/eagle-carrying-a-shark-video/', 'https://www.snopes.com/fact-check/tom-brady-video-catch-machine/', 'https://www.snopes.com/fact-check/sucker-punch/', 'https://www.snopes.com/fact-check/baby-olympics-video/', 'https://www.snopes.com/fact-check/microscope-bugs-instant-ramen-video/', 'https://www.snopes.com/fact-check/zombie-chicken-video/', 'https://www.snopes.com/fact-check/clip-artless/', 'https://www.snopes.com/fact-check/viral-molten-copper-big-mac/', 'https://www.snopes.com/fact-check/gabby-petito-video-sandy-hook/', 'https://www.snopes.com/fact-check/ice-helix-polar-vortex-video/', 'https://www.snopes.com/fact-check/kyle-rittenhouse-punch-woman-video/', 'https://www.snopes.com/fact-check/hurricane-dorian-near-florida/', 'https://www.snopes.com/fact-check/scarlett-johansson-woman-disappears/', 'https://www.snopes.com/fact-check/video-indonesia-cloud/', 'https://www.snopes.com/fact-check/cnn-israel-exploding-goats-hezbollah/', 'https://www.snopes.com/fact-check/trump-northam-abortion-execute/', 'https://www.snopes.com/fact-check/footage-inside-plane-crashed-nepal/', 'https://www.snopes.com/fact-check/video-volcano-iceland/', 'https://www.snopes.com/fact-check/amazing-catch-ball-girl/', 'https://www.snopes.com/fact-check/double-trouble/', 'https://www.snopes.com/fact-check/video-bye-bye/', 'https://www.snopes.com/fact-check/baby-dunking-video/', 'https://www.snopes.com/fact-check/abc-video-syrian-war-footage/', 'https://www.snopes.com/fact-check/false-footaging/', 'https://www.snopes.com/fact-check/asteroid-moon-collision/', 'https://www.snopes.com/fact-check/churchill-waterslide-video/', 'https://www.snopes.com/fact-check/puppy-butterfly-video-real/', 'https://www.snopes.com/fact-check/avoiding-future-plague-psa/', 'https://www.snopes.com/fact-check/real-video-arrow-always-points-right/']\n",
      "URLs saved to ./input.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def get_snopes_fact_check_urls(search_term,page_num):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    url = f\"https://www.snopes.com/search/?q={search_term}#gsc.tab=0&gsc.q={search_term}&gsc.page={page_num}\"\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 7).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"gs-title\"))\n",
    "        )\n",
    "\n",
    "        links = driver.find_elements(By.CLASS_NAME, \"gs-title\")\n",
    "\n",
    "        fact_check_urls = []\n",
    "        for link in links:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href and \"https://www.snopes.com/fact-check\" in href:\n",
    "                fact_check_urls.append(href)\n",
    "\n",
    "        return fact_check_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_urls = []\n",
    "    for page_num in range(1, 10):\n",
    "        urls = get_snopes_fact_check_urls(\"video\", page_num)\n",
    "        if urls:\n",
    "            switch_count=True\n",
    "            print(f\"Found the following fact-check URLs on page {page_num}:\")\n",
    "            for url in urls:\n",
    "                if(switch_count):\n",
    "                  print(url)\n",
    "                  all_urls.append(url)\n",
    "                  switch_count=False\n",
    "                else:\n",
    "                  switch_count=True\n",
    "        else:\n",
    "            print(f\"No fact-check URLs found on page {page_num}.\")\n",
    "\n",
    "    print(\"\\nAll collected URLs:\")\n",
    "    print(all_urls)\n",
    "\n",
    "    filepath = os.path.join(\".\", \"input.txt\")\n",
    "    try:\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for url in all_urls:\n",
    "                f.write(url + \"\\n\")\n",
    "        print(f\"URLs saved to {filepath}\")\n",
    "    except Exception as e:\n",
    "      print(\"Could not save to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BS4 Scraping + JSON Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 95 videos to be processed.\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_1.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 1)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_2.mp4\n",
      "Error: Could not find the description in the JSON data.  KeyError: 'itemInfo'\n",
      "JSON structure may have changed. Check the path to the 'desc' field.\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 2)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [TikTok] 7012463416216489218: Video not available, status code 10222; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find the description in the JSON data.  KeyError: 'itemInfo'\n",
      "JSON structure may have changed. Check the path to the 'desc' field.\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 3)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unsupported URL: https://x.com/realDonaldTrump?ref_src=twsrc%5Etfw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Tweet text not found within the time limit for URL: https://twitter.com/realDonaldTrump?ref_src=twsrc%5Etfw\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 4)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_5.mp4\n",
      "Unsupported URL: https://www.facebook.com/ionflix/videos/1829274207291885/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 5)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [Reddit] tsw5nk8s6fe81: Requested format is not available. Use --list-formats for a list of available formats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 6)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_7.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 7)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_8.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 8)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 9)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 10)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_11.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 11)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 12)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_13.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 13)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 14)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1265855459719892993: No video could be found in this tweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 15)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [facebook] 2548841225330935: No video formats found!; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/CambioDigital/videos/2548841225330935/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 16)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_17.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 17)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_18.mp4\n",
      "Unsupported URL: https://www.facebook.com/groups/441227163449213/permalink/802269580678301/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 18)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [Imgur] 1uZWelJ: Unable to download JSON metadata: HTTP Error 404: Not Found (caused by <HTTPError 404: Not Found>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 19)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_20.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 20)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [facebook] 10159034024061460: This video is only available for registered users. Use --cookies, --cookies-from-browser, --username and --password, --netrc-cmd, or --netrc (facebook) to provide account credentials. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/35499336459/posts/10159034024061460\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 21)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 22)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_23.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 23)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1650863463634448388: NSFW tweet requires authentication. Use --cookies, --cookies-from-browser, --username and --password, --netrc-cmd, or --netrc (twitter) to provide account credentials. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Tweet text not found within the time limit for URL: https://twitter.com/reserch_human/status/1650863463634448388\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 24)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_25.mp4\n",
      "Unsupported URL: https://www.facebook.com/melaniemellymel13/posts/pfbid021YAzNH51e4j8UzDgYwmBuPWnyoLqBUXtwPPUEt4VsQFPXAFXBrgMDMsuAmepJU2Ul?__cft__[0]=AZVe1HoJ5XAINEAHZlsBkSlGDgjVuldDcQaz7sebin3ovH0rdoa9JZiLmOLngUeJh8xbhjWNgbkuh0_MrMXtxYqfP1gC6Z4XZuH6E6Qe28adwLEtkPMpH_sHSA-AhL-xQlU-Xrg2c33wFN_ogJRBpnPTEmjRK75CwvrwaBBcVr8AUQ&__tn__=%2CO%2CP-R\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 25)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_26.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 26)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_27.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 27)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 28)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_29.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 29)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 30)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_31.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 31)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube:tab] ObamaSnippetsDotCom\": Unable to download API page: HTTP Error 404: Not Found (caused by <HTTPError 404: Not Found>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid YouTube URL.\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 32)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 33)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_34.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 34)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1227570288071716864: No video could be found in this tweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 35)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 36)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [Reddit] 1654hjw: HTTP Error 403 Forbidden; reason given: None; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 37)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_38.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 38)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1457804525427908608: No video could be found in this tweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 39)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_40.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 40)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_41.mp4\n",
      "Unsupported URL: https://www.facebook.com/MasterBert195/posts/393037023107806/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 41)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_42.mp4\n",
      "Unsupported URL: https://www.facebook.com/1787534361480226/videos/pcb.2141356472764678/2141354776098181/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 42)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] Oww5zb0XvHg: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 43)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_44.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 44)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_45.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 45)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1521701921563815937: Suspended\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Tweet text not found within the time limit for URL: https://twitter.com/labian1807/status/1521701921563815937\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 46)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_47.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 47)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_48.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 48)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [twitter] 1867317812450246759: No video could be found in this tweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 49)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_50.mp4\n",
      "Unsupported URL: https://www.facebook.com/AiydaNurhidayah/videos/327356836054673/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 50)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_51.mp4\n",
      "Unsupported URL: https://www.facebook.com/158383721771326/videos/468183177282071/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 51)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_52.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 52)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 53)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_54.mp4\n",
      "Unsupported URL: https://www.facebook.com/oribejerano/videos/1099197442007821/?rdid=nYzA94G7b942VFB6\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 54)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 55)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 56)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unsupported URL: https://www.facebook.com/photo?fbid=10158003446139620&set=pcb.3242033472584438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/photo?fbid=10158003446139620&set=pcb.3242033472584438\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 57)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_58.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 58)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_59.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 59)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unsupported URL: https://www.facebook.com/YodaBBYABY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/YodaBBYABY\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 60)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_61.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 61)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [facebook] 512515981158720: No video formats found!; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/reel/512515981158720\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 62)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 63)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 64)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] tWVQFtYpGnY: Video unavailable. This video is no longer available due to a copyright claim by Rick Lax Entertainment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 65)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unsupported URL: https://x.com/adubb1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout: Tweet text not found within the time limit for URL: https://twitter.com/adubb1022\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 66)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [instagram:user] warmnfuzzy.tv: Unable to extract data; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.instagram.com/warmnfuzzy.tv/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 67)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 68)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_69.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 69)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [TikTok] 7434566887276662049: Video not available, status code 100004; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find the description in the JSON data.  KeyError: 'webapp.video-detail'\n",
      "JSON structure may have changed. Check the path to the 'desc' field.\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 70)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [facebook] 2731565820205672: Cannot parse data; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/xyxmfn/videos/vb.238815406778496/2731565820205672/?type=2&theater\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 71)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 72)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Invalid YouTube URL.\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 73)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_74.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 74)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_75.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 75)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 76)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_77.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 77)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_78.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 78)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_79.mp4\n",
      "Unsupported URL: https://www.instagram.com/p/DCYcf5syKeV/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 79)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_80.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 80)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 81)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] fQupQPCEw4U: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 82)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_83.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 83)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_84.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 84)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 85)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 86)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_87.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 87)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] BuO6yJrRAYw: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 88)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 89)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [facebook] 448116063831287: No video formats found!; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported URL: https://www.facebook.com/watch/?v=448116063831287\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 90)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_91.mp4\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 91)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 92)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 93)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Video downloaded to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/downloaded_videos/video_94.mp4\n",
      "Unsupported URL: https://www.instagram.com/p/BiMxAXalARt/\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 94)\n",
      "Next video processing\n",
      "\n",
      "\n",
      "Error fetching URL: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error fetching URL: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error fetching URL: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error getting rating: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error fetching URL for rating context: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error fetching URL: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Error fetching URL: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
      "Video data saved to /fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/video_data.json (after processing video 95)\n",
      "Next video processing\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import yt_dlp\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "\n",
    "\n",
    "def get_headline(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_container = soup.find('section', class_='title-container')\n",
    "        if title_container:\n",
    "            headline_tag = title_container.find('h1')\n",
    "            return headline_tag.text.strip() if headline_tag else None\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_subheadline(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title_container = soup.find('section', class_='title-container')\n",
    "        if title_container:\n",
    "            subheadline_tag = title_container.find('h2')\n",
    "            return subheadline_tag.text.strip() if subheadline_tag else None\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def _get_social_media_platform(link):\n",
    "    if not link:\n",
    "        return None\n",
    "\n",
    "    social_media_domains = {\n",
    "        \"tiktok.com\": \"tiktok\",\n",
    "        \"youtube.com\": \"youtube\",\n",
    "        \"twitter.com\": \"twitter\",\n",
    "        \"x.com\": \"twitter\",\n",
    "        \"facebook.com\": \"facebook\",\n",
    "        \"reddit.com\": \"reddit\",\n",
    "        \"instagram.com\": \"instagram\",\n",
    "    }\n",
    "\n",
    "    for domain, platform_name in social_media_domains.items():\n",
    "        if domain in link:\n",
    "            return platform_name\n",
    "    return None\n",
    "\n",
    "def get_rating(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        rating_div = soup.find('div', class_='rating_title_wrap')\n",
    "        if rating_div:\n",
    "            for child in rating_div.children:\n",
    "                if child.string and child.string.strip():\n",
    "                    return child.string.strip()\n",
    "        return None\n",
    "\n",
    "    except (requests.exceptions.RequestException, Exception) as e:\n",
    "        print(f\"Error getting rating: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_rating_context(url):\n",
    "    \"\"\"Gets the text content of the claim_cont div.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        claim_div = soup.find('div', class_='claim_cont')\n",
    "        if claim_div:\n",
    "            return claim_div.text.strip()\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL for rating context: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while getting rating context: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_links_from_article_rail(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        youtube_container = soup.find('div', class_='embed_container youtube_container')\n",
    "        if youtube_container:\n",
    "            iframe = youtube_container.find('iframe', attrs={'data-src': True})\n",
    "            if iframe and 'youtube.com/embed' in iframe['data-src']:\n",
    "                return [iframe['data-src']]\n",
    "            iframe = youtube_container.find('iframe', attrs={'src': True})\n",
    "            if iframe and 'youtube.com/embed' in iframe['src']:\n",
    "              return [iframe['src']]\n",
    "\n",
    "        article_rail_wrapper = soup.find('div', class_='article_rail_wrapper')\n",
    "        if article_rail_wrapper:\n",
    "            links = []\n",
    "            for a_tag in article_rail_wrapper.find_all('a', href=True):\n",
    "                links.append(a_tag['href'])\n",
    "            return links\n",
    "        return []\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_first_social_link(url):\n",
    "    links = get_links_from_article_rail(url)\n",
    "    if not links:\n",
    "        return None\n",
    "\n",
    "    social_media_patterns = [\n",
    "        r'https?://(?:www\\.)?tiktok\\.com',\n",
    "        r'https?://(?:www\\.)?youtube\\.com',\n",
    "        r'https?://(?:www\\.)?(?:twitter\\.com|x\\.com)',\n",
    "        r'https?://(?:www\\.)?facebook\\.com',\n",
    "        r'https?://(?:www\\.)?reddit\\.com',\n",
    "        r'https?://(?:www\\.)?instagram\\.com',\n",
    "    ]\n",
    "\n",
    "    for link in links:\n",
    "        for pattern in social_media_patterns:\n",
    "            if re.match(pattern, link):\n",
    "                return link\n",
    "\n",
    "    return \"No link associated with article found.\"\n",
    "\n",
    "\n",
    "def download_video(url, output_dir, output_filename=\"downloaded_video.mp4\", verbose=False):\n",
    "    \"\"\"Downloads a video and saves it to the specified directory.\"\"\"\n",
    "    try:\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        ydl_opts = {\n",
    "            'format': 'best',\n",
    "            'outtmpl': os.path.join(output_dir, 'temp_download.%(ext)s'),\n",
    "            'quiet': not verbose,\n",
    "            'no_warnings': True,\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info_dict = ydl.extract_info(url, download=False)\n",
    "            duration = info_dict.get('duration')\n",
    "\n",
    "            if duration is None:\n",
    "                 return False, \"Could not determine video duration.\", None\n",
    "\n",
    "            if duration > 600:\n",
    "                return False, \"Video exceeds 10-minute limit.\", duration\n",
    "\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            downloaded_filename = ydl.prepare_filename(info_dict)\n",
    "\n",
    "\n",
    "        _, ext = os.path.splitext(downloaded_filename)\n",
    "        if ext.lower() == '.mp4':\n",
    "            os.rename(downloaded_filename, output_path)\n",
    "            return True, \"Successfully downloaded and renamed to MP4.\", duration\n",
    "\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', downloaded_filename,\n",
    "            '-c:v', 'libx264',\n",
    "            '-c:a', 'aac',\n",
    "            '-strict', 'experimental',\n",
    "            '-y',\n",
    "             output_path\n",
    "        ]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Running ffmpeg command: {' '.join(command)}\")\n",
    "\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            error_message = f\"FFmpeg conversion failed:\\nReturn code: {result.returncode}\\nStdout: {result.stdout}\\nStderr: {result.stderr}\"\n",
    "            if verbose:\n",
    "                print(error_message)\n",
    "            os.remove(downloaded_filename)\n",
    "            return False, error_message, None\n",
    "        else:\n",
    "            if verbose:\n",
    "              print(\"FFmpeg conversion successful.\")\n",
    "            os.remove(downloaded_filename)\n",
    "            return True, \"Successfully downloaded and converted to MP4.\", duration\n",
    "\n",
    "    except yt_dlp.utils.DownloadError as e:\n",
    "        return False, f\"yt-dlp download error: {e}\", None\n",
    "    except FileNotFoundError:\n",
    "        return False, \"ffmpeg not found.  Please make sure ffmpeg is installed and in your system's PATH.\", None\n",
    "    except Exception as e:\n",
    "        return False, f\"An unexpected error occurred: {e}\", None\n",
    "\n",
    "\n",
    "def download_progress_hook(d):\n",
    "    if d['status'] == 'downloading':\n",
    "        print(f\"Downloading: {d['_percent_str']} {d['_speed_str']} ETA: {d['_eta_str']}\", end='\\r')\n",
    "    elif d['status'] == 'finished':\n",
    "        print(f\"\\nDownloaded: {d['filename']}\")\n",
    "\n",
    "\n",
    "def get_youtube_description(url):\n",
    "    try:\n",
    "        match = re.search(r\"(?:embed/|v/|\\?v=|&v=|\\.be/)([\\w-]+)\", url)\n",
    "        if not match:\n",
    "            match = re.search(r\"youtube\\.com/watch\\?.*([\\w-]+)\", url)\n",
    "            if not match:\n",
    "                print(\"Invalid YouTube URL.\")\n",
    "                return None\n",
    "        video_id = match.group(1)\n",
    "        watch_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "        response = requests.get(watch_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pattern = re.compile(r'(?<=shortDescription\":\").*?(?=\",\"isCrawlable)')\n",
    "        match = pattern.search(str(soup))\n",
    "\n",
    "        if match:\n",
    "            description = match.group(0).replace('\\\\n', '\\n').replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n",
    "            return description\n",
    "        else:\n",
    "            desc_tag = soup.find('meta', attrs={'name': 'description'})\n",
    "            if desc_tag and desc_tag.get('content'):\n",
    "                return desc_tag.get('content')\n",
    "            print(\"Description not found using primary or secondary methods.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_tweet_text(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            tweet_text_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]'))\n",
    "            )\n",
    "            spans = tweet_text_element.find_elements(By.TAG_NAME, 'span')\n",
    "            tweet_text = \"\".join([span.text for span in spans])\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout: Tweet text not found within the time limit for URL: {url}\")\n",
    "            tweet_text = None\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Error: Tweet element not found for URL: {url}\")\n",
    "            tweet_text = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        tweet_text = None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return tweet_text\n",
    "\n",
    "\n",
    "def get_tiktok_description(tiktok_url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Referer': 'https://www.tiktok.com/',\n",
    "        }\n",
    "        response = requests.get(tiktok_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        script_tag = soup.find('script', {'id': '__UNIVERSAL_DATA_FOR_REHYDRATION__'})\n",
    "\n",
    "        if not script_tag:\n",
    "            print(\"Error: Could not find the '__UNIVERSAL_DATA_FOR_REHYDRATION__' script tag.\")\n",
    "            return None\n",
    "        json_data = json.loads(script_tag.string)\n",
    "\n",
    "        try:\n",
    "            description = json_data['__DEFAULT_SCOPE__']['webapp.video-detail']['itemInfo']['itemStruct']['desc']\n",
    "            return description\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Could not find the description in the JSON data.  KeyError: {e}\")\n",
    "            print(\"JSON structure may have changed. Check the path to the 'desc' field.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: Request failed: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: JSON decoding failed: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_tiktok_video_id(url):\n",
    "    \"\"\"Extracts the video ID from a TikTok URL. Supports various URL formats.\"\"\"\n",
    "    match = re.search(r'/video/(\\d+)', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_seo_canonical_url(tiktok_url: str) -> str:\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(tiktok_url, headers=headers, allow_redirects=True, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        script_tag = soup.find('script', {'id': '__UNIVERSAL_DATA_FOR_REHYDRATION__'})\n",
    "        if not script_tag:\n",
    "            print(\"Error: Could not find the '__UNIVERSAL_DATA_FOR_REHYDRATION__' script tag.\")\n",
    "            return None, None\n",
    "\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        try:\n",
    "            canonical_url = json_data['__DEFAULT_SCOPE__']['seo.abtest']['canonical']\n",
    "        except:\n",
    "            canonical_url = None\n",
    "\n",
    "        video_id = get_tiktok_video_id(canonical_url)\n",
    "        if video_id is None:\n",
    "            video_id = get_tiktok_video_id(tiktok_url)\n",
    "\n",
    "        return canonical_url, video_id\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def get_reddit_post_title(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        title_element = soup.select_one('[id^=\"post-title-\"]')\n",
    "        if title_element:\n",
    "            return title_element.text.strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_content_from_url(url):\n",
    "    try:\n",
    "        if \"youtube.com\" in url or \"youtu.be\" in url:\n",
    "            description = get_youtube_description(url)\n",
    "            if description:\n",
    "                return {\"site_type\": \"youtube\", \"content\": description}\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        elif \"twitter.com\" in url or \"x.com\" in url:\n",
    "            tweet_text = get_tweet_text(url)\n",
    "            if tweet_text:\n",
    "                return {\"site_type\": \"twitter\", \"content\": tweet_text}\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        elif \"tiktok.com\" in url:\n",
    "            canonical_url, video_id = get_seo_canonical_url(url)\n",
    "            if canonical_url:\n",
    "                description = get_tiktok_description(canonical_url)\n",
    "            else:\n",
    "                 description = get_tiktok_description(url)\n",
    "            if description is not None: \n",
    "                return {\"site_type\": \"tiktok\", \"content\": description}\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        elif \"reddit.com\" in url:\n",
    "            title = get_reddit_post_title(url)\n",
    "            if title:\n",
    "                return {\"site_type\": \"reddit\", \"content\": title}\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Unsupported URL: {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error in get_content_from_url: {e}\")\n",
    "        return None\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_sentences_with_links(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        results = {}\n",
    "\n",
    "        p_tags = soup.find_all('p')\n",
    "        for p_tag in p_tags:\n",
    "            links = p_tag.find_all('a', href=True)\n",
    "            if links:\n",
    "                full_text = ' '.join(p_tag.get_text(separator=\" \", strip=True).split())\n",
    "                link_dict = {\n",
    "                    ' '.join(link.get_text(separator=\" \", strip=True).split()): link['href']\n",
    "                    for link in links\n",
    "                }\n",
    "                results[full_text] = link_dict\n",
    "\n",
    "        blockquote_tags = soup.find_all('blockquote')\n",
    "        for blockquote_tag in blockquote_tags:\n",
    "            links = blockquote_tag.find_all('a', href=True)\n",
    "            if links:\n",
    "                full_text = ' '.join(blockquote_tag.get_text(separator=\" \", strip=True).split())\n",
    "                link_dict = {\n",
    "                    ' '.join(link.get_text(separator=\" \", strip=True).split()): link['href']\n",
    "                    for link in links\n",
    "                }\n",
    "                results[full_text] = link_dict\n",
    "\n",
    "        return results\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL: {e}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video_count = 1  # DO NOT MODIFY USED FOR LABELING\n",
    "    results = []\n",
    "\n",
    "    input_file = \"input.txt\"\n",
    "    download_dir = \"/fs/clip-projects/rlab/atrey/ooc-misinformation/scraping/snopes\"\n",
    "    output_json_path = os.path.join(\"/fs/clip-projects/rlab/atrey/ooc-misinformation/scraping\", \"video_data_snopes.json\")\n",
    "\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    try:\n",
    "        with open(input_file, \"r\") as f:\n",
    "            all_urls = [line.strip() for line in f]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"There are {len(all_urls)} videos to be processed.\")\n",
    "\n",
    "    for URL in all_urls:\n",
    "        headline = get_headline(URL)\n",
    "        subheadline = get_subheadline(URL)\n",
    "        social_platform = _get_social_media_platform(get_first_social_link(URL))\n",
    "        rating = get_rating(URL)\n",
    "        rating_context = get_rating_context(URL)\n",
    "        social_link = get_first_social_link(URL)\n",
    "        destination_path = None\n",
    "        download_success = False\n",
    "        social_text = None\n",
    "        video_duration = None\n",
    "        external = extract_sentences_with_links(URL)\n",
    "\n",
    "        if social_link and social_link != \"No link associated with article found.\":\n",
    "            download_success, download_message, duration = download_video(social_link, download_dir, output_filename=f\"video_{video_count}.mp4\")\n",
    "            if download_success:\n",
    "                destination_path = os.path.join(download_dir, f\"video_{video_count}.mp4\")\n",
    "                print(f\"Video downloaded to {destination_path}\")\n",
    "            video_duration = duration\n",
    "            content_result = get_content_from_url(social_link)\n",
    "            if content_result:\n",
    "                social_text = content_result['content']\n",
    "        else:\n",
    "            download_message = \"No social media link found, skipping download.\"\n",
    "\n",
    "        video_data = {\n",
    "            'snope_url': URL,\n",
    "            'snope_headline': headline,\n",
    "            'snope_subheadline': subheadline,\n",
    "            'social_platform': social_platform,\n",
    "            'rating': rating,\n",
    "            'rating_context': rating_context,\n",
    "            'social_link': social_link,\n",
    "            'social_duration': video_duration,\n",
    "            'social_text': social_text,\n",
    "            'external': external,\n",
    "            'download_success': download_success,\n",
    "            'download_message': download_message,\n",
    "            'drive_path': destination_path,\n",
    "        }\n",
    "        results.append(video_data)\n",
    "\n",
    "        try:\n",
    "            with open(output_json_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "            print(f\"Video data saved to {output_json_path} (after processing video {video_count})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to JSON file: {e}\")\n",
    "\n",
    "        video_count += 1\n",
    "        print(\"Next video processing\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ooc-misinformation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
